# Set path

```{r}

setwd("D:\\Data Science ToolBox\\Practise\\ML for Hacker\\Data set")

```

#Load library

```{r}

library(anytime)
library(e1071)
library(randomForest)
library(caret)

```

# Load data

```{r}

pml_training <- read.csv("pml-training.csv",header = TRUE, stringsAsFactors = FALSE)
pml_testing <- read.csv("pml-testing.csv",header = TRUE, stringsAsFactors = FALSE)

```

# Data dimension

```{r}
dim(pml_training) 
```

# Structure data

```{r}
str(pml_training)
```

# Summary data

```{r}

summary(pml_training)

```

# As we can see, our data set has so many features but a lot of these have missing or
# inconsistent values. Now i try to process them.

```{r}
na <- colSums(sapply(pml_training, is.na))
sum(na!=0)
```

# Name of features which include missing values

```{r}
names(na[na!=0])

```

# Ratio of missing values in these features will presented as following:

```{r}

colSums(sapply(pml_training, is.na))/nrow(pml_training)*100

```

# Ratio of missing values are greater than 90%. So i decided to remove the features which have many missing values.

```{r}
index <- which(na!=0)
pml_training[,index] <- NULL
```

# Test the data set and view structure of the data one more time.


```{r}
sum(is.na(pml_training))
str(pml_training)
```

# Our data set still has a lot of inconsistent values.Now, I convert almost the features to numeric
# without user_name, cvtd_timestamp, new_window and classe.

```{r}
without <- which(!names(pml_training)%in%c("user_name","cvtd_timestamp","new_window","classe"))

for (item in without){
  pml_training[,item] <- as.numeric(pml_training[,item])
}

```

# Recalculate missing values
```{r}
na <- colSums(sapply(pml_training, is.na))
sum(na!=0)
colSums(sapply(pml_training, is.na))/nrow(pml_training)*100
```
# Still many missing values.I'll delete it now.
```{r}
index <- which(na!=0)
pml_training[,index] <- NULL
```

# Convert raw_timestamp_part_1, raw_timestamp_part_2 to time

```{r}
pml_training$raw_timestamp_part_1 <- anytime(pml_training$raw_timestamp_part_1)
pml_training$raw_timestamp_part_2 <- anytime(pml_training$raw_timestamp_part_2)

```

# Now, the data is quite clean.The similar, i do it on pml_testing.

```{r}

na <- colSums(sapply(pml_testing, is.na))
sum(na!=0)
colSums(sapply(pml_testing, is.na))/nrow(pml_testing)*100
index <- which(na!=0)
pml_testing[,index] <- NULL
pml_testing$problem_id <- NULL
pml_testing$raw_timestamp_part_1 <- anytime(pml_testing$raw_timestamp_part_1)
pml_testing$raw_timestamp_part_2 <- anytime(pml_testing$raw_timestamp_part_2)
pml_testing$user_name <- as.factor(pml_testing$user_name)
pml_testing$new_window <- as.factor(pml_testing$new_window)
without <- which(!names(pml_testing)%in%c("user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","classe"))
for (item in without){
  pml_testing[,item] <- as.numeric(pml_testing[,item])
}
```

# MODEL SELECTION

```{r}
pml_training$classe <- as.factor(pml_training$classe)
pml_training$user_name <- as.factor(pml_training$user_name)
pml_training$new_window <- as.factor(pml_training$new_window)
```

# Devide the data into training set and testing set using bootstrap method

```{r}
inTrain <- createDataPartition(pml_training$classe, p = 0.632, list = FALSE)
training <- pml_training[inTrain,]
testing <- pml_training[-inTrain,]
```

# Model 1: Support Vector Machine

```{r}
modelsvm <- svm(classe~., data = training[,-c(1,3,4,5)])
predsvm <- predict(modelsvm, newdata = testing)
confusionMatrix(predsvm,testing$classe)
```

# Model 2: Random Forest

```{r}
modelrf <- randomForest(classe~., data = training[,-c(1,3,4,5)], n.trees = 500)
predrf <- predict (modelrf,newdata = testing)
confusionMatrix(predrf,testing$classe)
```

# Model 3 : K-nearest neighbors 
```{r}
trctrl <- trainControl(method = "boot632", number = 10, repeats = 3)
modelknn <- train(classe~., data = training, method = "knn", 
                  trControl = trctrl,
                  preProcess = c("center", "scale"),
                  tuneLength = 10)
modelknn <- train(classe~., data = training[,-c(1,3,4,5)], method = "knn")
predknn <- predict (modelknn, newdata = testing)
confusionMatrix(predknn, testing$classe)
```

# After 3 models, we immediately see that, Random forest is the best model with accuracy up to 99.56%
# knn is also good with 97.92% of accuracy. The last one is svm. 

# Final Prediction
```{r}
levels(pml_testing$new_window) <- levels(pml_training$new_window)
predrf2 <- predict(modelrf, newdata = pml_testing)
predknn2 <- predict(modelknn, newdata = pml_testing)
predsvm2 <- predict(modelsvm, newdata = pml_testing)
```

# Create a data frame to compare the result
```{r}
comparision <- data.frame("svm" = predsvm2, "rf" = predrf2, "knn" = predknn2)
```